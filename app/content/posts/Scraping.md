---
title: "How to web scraping improved my finances"
excerpt: "Helps to reduce unnecesary expenses"
date: "2024-08-31"
author: "Javier Medina"
---



**Introducción:**
El web scraping es una técnica poderosa que me ha permitido automatizar la recopilación de datos y tomar decisiones informadas al momento de hacer compras. En mi caso, desarrollé un proyecto con **JavaScript**, utilizando **Puppeteer** para scrappear las ofertas de los supermercados de mi zona, **Express** para generar una API que sirviera los datos, y tecnologías como **GitHub Actions** para la automatización y **Azure** para el despliegue del backend. El frontend lo construí con **Vite.js** y lo desplegué en **Vercel**.

Este proyecto no solo me ayudó a mejorar mi economía personal, sino que también se convirtió en una idea vendible para otras personas o negocios que buscan optimizar sus gastos.

### **El proyecto en detalle**

1. **Web Scraping con Puppeteer**
Mi proyecto comienza con la recolección automática de ofertas diarias de supermercados como Jumbo, Carrefour y Dia. Utilizo **Puppeteer**, una herramienta que me permite interactuar con las páginas web y extraer la información que necesito, como los precios y las promociones de los productos.
2. **Backend con Express**
Toda la información scrappeada se procesa y se expone a través de una API creada con **Express**. Esta API organiza los datos y los sirve en formato **JSON**, lo que facilita su uso tanto para mi aplicación como para otros servicios.
3. **Automatización con GitHub Actions**
La magia del proyecto está en la automatización. Utilizo **GitHub Actions** para ejecutar mis scrapers de forma automática cada 12 horas. De esta manera, siempre tengo la información más actualizada sin tener que hacerlo manualmente.
4. **Despliegue en Azure**
El backend lo despliego en **Azure**, lo que me proporciona estabilidad y escalabilidad a un costo muy bajo, aprovechando los créditos gratuitos que ofrecen a estudiantes. Esta solución en la nube me asegura que la API esté siempre disponible.
5. **Frontend con Vite.js y Vercel**
Para el frontend, decidí utilizar **Vite.js** por su rapidez y simplicidad. Toda la interfaz está desplegada en **Vercel**, lo que me permite tener una aplicación ligera y rápida para visualizar las ofertas.

---

### **¿Cómo me ayudó a mejorar mi economía?**

Gracias a este proyecto, puedo ver todas las ofertas disponibles en los supermercados de mi zona en tiempo real. Esto me ha permitido:

- **Comparar precios** de manera rápida y eficiente.
- **Tomar decisiones inteligentes** sobre dónde comprar para ahorrar dinero.
- **Evitar desplazamientos innecesarios**, ya que sé exactamente a qué supermercado ir.

Además, esta idea tiene el potencial de escalar. He considerado ofrecer este servicio a pequeños negocios que quieren optimizar sus compras o incluso a consumidores que buscan ahorrar en sus compras diarias. Lo que empezó como una herramienta personal se ha convertido en una propuesta de valor interesante para otros.

---

### **Conclusión**

El web scraping es una herramienta poderosa no solo para automatizar tareas, sino también para tomar decisiones más informadas en el día a día. Mi proyecto ha mejorado mi economía y me ha abierto las puertas a nuevas oportunidades para vender esta solución a otras personas.